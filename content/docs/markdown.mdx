---
title: My Markdown
description: My Markdown
---

## Retrieval Augmented Generation (RAG)

æª¢ç´¢å¢å¼·ç”Ÿæˆ
æ–‡ç« é›£æ˜“åº¦ï¼šâ˜…â˜…â˜†â˜†â˜†

ğŸŒŸ æœ¬ç¯‡è‘—é‡åœ¨
- **ä»€éº¼æ˜¯ RAG åŠå…¶æ‡‰ç”¨**

ğŸŒŸ éç¨‹ä¸­æœƒç°¡ä»‹
- ä»€éº¼æ˜¯ LLMï¼ŒèƒŒå¾Œé‹ä½œæ©Ÿåˆ¶æ¦‚å¿µ
- ä»€éº¼æ˜¯ NLP

ğŸŒŸ æœ€å¾Œå¸¶å…¥ä¸€äº›å¯¦éš›é—œæ–¼ RAG çš„ç¯„ä¾‹

```mermaid
graph LR
    subgraph Pod
    s(service)
    f(fluent-bit)
    end
```

## â“ What is LLM
âœ… ä¸€å€‹æ–‡å­—æ¥é¾çš„ç”Ÿæˆå¼æ¨¡å‹
- LLMçš„å›æ‡‰ç”Ÿæˆï¼Œå¯ä»¥ç²—ç•¥çš„è¦–ç‚º
    ğŸ‘‰ å›æ‡‰å¥å­çš„æ¯ä¸€å€‹å­—éƒ½æ˜¯æ©Ÿç‡ç®—å‡ºä¾†çš„
    ğŸ‘‰ ä¸”æ¯å€‹ä½ç½®çš„æ¯å€‹å­—ï¼Œå…¶æ©Ÿç‡éƒ½ä¸åŒ

    | ç¬¬ä¸€å€‹å­—ç”Ÿæˆ | é¸æ“‡               |
    | ------------ | ------------------ |
    | æˆ‘ï¼š 10%     |
    | å°ï¼š 80%     | âœ… |
    | ç£ï¼š 15%     |
    | ...          |
    | æ˜¯ï¼š 55%     |
    | ç‰ï¼š 45%     |
    | å±±ï¼š 25%     |

    ğŸ‘‰ LLMç”Ÿæˆï¼šå°

    | ç¬¬äºŒå€‹å­—ç”Ÿæˆ | é¸æ“‡               |
    | ------------ | ------------------ |
    | æˆ‘ï¼š 10%     |                    |
    | å°ï¼š 25%     |                    |
    | ç£ï¼š 70%     | âœ… |
    | ...          |                    |
    | æ˜¯ï¼š 30%     |                    |
    | ç‰ï¼š 45%     |                    |
    | å±±ï¼š 35%     |                    |

    ğŸ‘‰ LLMç”Ÿæˆï¼šå°ç£

âœ… æœ‰æ™‚æœƒç”¢ç”Ÿå¹»è¦º
- æ©Ÿç‡çš„æ–‡å­—æ¥é¾
    ğŸ‘‰ ç”±æ–¼å›æ‡‰çš„å…§å®¹éƒ½æ˜¯æ©Ÿç‡ç®—å‡ºä¾†çš„ï¼Œæ‰€ä»¥ä»–å°æ–¼ã€Œè‡ªå·±çŸ¥é“ä»€éº¼ èˆ‡ ä¸çŸ¥é“ä»€éº¼ã€æ˜¯æ²’æœ‰è¾¦æ³•ç­è§£çš„

âœ… æ²’æœ‰èªçŸ¥é‚Šç•Œ

## â“ What is NLP
âœ… NLP(Natural Language Processing) å³æ˜¯è‡ªç„¶èªè¨€è™•ç†
- ML çš„è¨“ç·´çµæœå¦‚æ½˜æœµæ‹‰çš„ç›’å­
    ğŸ‘‰ ML è¨“ç·´å‡ºä¾†çš„æ¨¡å‹ï¼Œæ¯æ¬¡çµæœçš„å¥½å£æ˜¯è¼ƒé›£ä»¥é æ¸¬ï¼Œä¸”è²»æ™‚
    ğŸ‘‰ NLP çš„è¨“ç·´éç¨‹èˆ‡çµæœç›¸å°å®¹æ˜“æ§åˆ¶

## â“ What is RAG
âœ… RAG æ˜¯åŸºæ–¼ NLP ç™¼å±•å‡ºä¾†çš„ä¸€ç¨®æŠ€è¡“

âœ… ç‚º LLM åŠ ä¸Šå¤–æ›
- ä½¿ç”¨æ—¢æœ‰çš„ LLM å¤–æ›æˆ‘å€‘çš„è³‡æ–™
    ğŸ‘‰ å‰é¢æåˆ° LLM ä¸¦æ²’æœ‰ã€ŒèªçŸ¥é‚Šç•Œã€ï¼Œåœ¨ RAG é€éæŠŠ ç‰¹å®šç¯„åœçš„çŸ¥è­˜ ***å¤–æ›*** çµ¦ LLMï¼Œä½¿å…¶å¯ä»¥é‡å°è©²çŸ¥è­˜é›†è³‡æ–™å›ç­”å•é¡Œ

âœ… è¨“ç·´æˆæœ¬ä½



## RAG æœ€åŸºæœ¬çš„å¯ä»¥åˆ†æˆå…©å¤§éƒ¨åˆ†

1. è³‡æ–™å¤–æ›
2. è³‡æ–™æª¢ç´¢èˆ‡ç”Ÿæˆ

### ğŸŒŸ è³‡æ–™å¤–æ›
å°‡ LLM çš„èªçŸ¥ç¯„åœï¼Œé™ç¸®é–å®šåœ¨æˆ‘å€‘å¸Œæœ›çš„ç‰¹å®šç¯„åœå…§
æˆ‘å€‘æœƒå°‡é€™äº›ç‰¹å®šç¯„åœçš„è³‡æ–™ï¼Œä»¥ Embedding çš„æ–¹å¼å„²å­˜åœ¨è³‡æ–™åº«

*Embedding æ˜¯ä¸€ç¨®å°‡ç‰©ä»¶(å¦‚ï¼šå–®è©ã€å¥å­ã€åœ–ç‰‡ã€æª”æ¡ˆ)å‘é‡åŒ–çš„æ–¹å¼(çµæœé€šå¸¸æ˜¯ä¸€å€‹æ•¸å­¸çŸ©é™£)*

â— ç”±æ–¼æ©Ÿå™¨ä¸¦ä¸èªå¾—æˆ‘å€‘çš„è‡ªç„¶èªè¨€ï¼Œåœ¨æ©Ÿå™¨çš„ä¸–ç•Œè£¡ï¼Œéƒ½æ˜¯ 0,1 çš„æ•¸å­—ï¼Œæ‰€ä»¥æˆ‘å€‘é€é Embedding çš„æŠ€è¡“ï¼Œæ©Ÿå™¨æ‰å¾—ä»¥èªå¾—æˆ‘å€‘çš„èªè¨€

### ğŸŒŸ è³‡æ–™æª¢ç´¢èˆ‡ç”Ÿæˆ
æœ‰äº†é€™äº›è³‡è¨Šï¼Œæˆ‘å€‘å³å¯é€é è‡ªç„¶èªè¨€çš„æ–¹å¼åšæå•(Query)ï¼ŒæŠŠ Query ä¹Ÿç”¨ Embedding çš„æ–¹å¼ï¼Œè®“æ©Ÿå™¨å»è³‡æ–™åº«æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è³‡è¨Š(Data)

æœ€å¾ŒæŠŠ Query + Data ç”¨è‡ªç„¶èªè¨€çš„æ–¹å¼æ•´åˆæˆä¸€å€‹ Prompt æä¾›çµ¦ LLM
è®“ LLM é‡å°é€™å€‹ Prompt ä¾†ç”¢ç”Ÿå›æ‡‰

## ğŸŒŸ Demo
ğŸ‘‰ è³‡æ–™(documents) Embeddingï¼Œä¸¦å„²å­˜åˆ°è³‡æ–™åº«(chromadb)
- LLM æ¨¡å‹ä½¿ç”¨ llama2
- è³‡æ–™åº«ä½¿ç”¨ ChromaDB

```python
import ollama
import chromadb

documents = [
  "Llamas are members of the camelid family meaning they're pretty closely related to vicuÃ±as and camels",
  "Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands",
  "Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall",
  "Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight",
  "Llamas are vegetarians and have very efficient digestive systems",
  "Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old",
]

client = chromadb.Client()

# collection exits ? use it || create one
try:
    collection = client.create_collection(name="docs")
except Exception as e:
    if "Collection docs already exists" in str(e):
        collection = client.get_collection(name="docs")
    else:
        raise e

# ID check
existing_docs = collection.get()
existing_ids = set(existing_docs['ids'])

# Document vectorize and store into vector database
for i, d in enumerate(documents):
    if str(i) in existing_ids:
        print(f"ID {i} already exists, skipping.")
        continue

    response = ollama.embeddings(model="mxbai-embed-large", prompt=d)
    embedding = response["embedding"]
    collection.add(
        ids=[str(i)],
        embeddings=[embedding],
        documents=[d]
    )
```

ğŸ‘‰ å°‡ Query Embedding å¾Œï¼Œåˆ°è³‡æ–™åº«æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è³‡æ–™(data)

```python
Query = "What animals are llamas related to?"

# vectorize and embeddings
response = ollama.embeddings(
  prompt=Query,
  model="mxbai-embed-large"
)
results = collection.query(
  query_embeddings=[response["embedding"]],
  n_results=1
)
data = results['documents'][0][0]
```

ğŸ‘‰ å°‡ Query + data æ•´åˆæˆä¸€å€‹ Prompt è®“ LLM é‡å°é€™å€‹ Prompt ç”¢ç”Ÿå›æ‡‰ ğŸ‘‰output['response']

```python
ollama.pull(model="llama2")
# response
output = ollama.generate(
  model="llama2",
  prompt=f"Using this data: {data}. Respond to this prompt: {Query}"
)

print(output['response'])
```
ğŸ‘‰ å›æ‡‰ç¯„ä¾‹
```
Llamas are members of the camelid family, which means they are closely related to other animals such as:

1. VicuÃ±as: VicuÃ±as are small, wild relatives of llamas and alpacas. They are native to South America and are known for their soft, woolly coats.
2. Camels: As the name suggests, camels are also members of the camelid family. They are known for their large size, long eyelashes, and ability to survive in hot, dry environments.
3. Alpacas: Alpacas are domesticated animals that are closely related to llamas and vicuÃ±as. They are native to South America and are known for their soft, luxurious fibers.

So, to summarize, llamas are related to vicuÃ±as, camels, and alpacas. These animals share similar physical and behavioral characteristics due to their shared evolutionary history within the camelid family.
```

---
å»¶ä¼¸é–±è®€ï¼š
- [RAG Optimize: Data-Chunk](https://hackmd.io/xOaOwrINQL6f7I5MTsPbgQ)

#### Figure-out
- infra of Re-Ranking(how does it works)
- collection schema design(base on what?)
- Active RAG

#### Optimize brainstorming (å¾…é©—è­‰)
- é€é Query æŒçºŒå¼·åŒ–å­¸ç¿’, two db control ( source-data / query optimize )
- mixture of GraphDB?
- optimize "prompt" with different type of Query question to execute different processes
- embedding full-context / key-context 

#### interface
- Slack
- Line

é—œéµå­— : AI, ML, NLP, RAG, Embeddings
